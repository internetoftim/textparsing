{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "# from spacy import doc\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from pathlib import PureWindowsPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_chunks(input_text):\n",
    "    doc = nlp(input_text)\n",
    "    spans = list(doc.ents)  #+ list(doc.noun_chunks)\n",
    "    out_list = []\n",
    "    for span in spans:\n",
    "        span.merge()\n",
    "        out_list.append(span)\n",
    "    return out_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_name_pair(name, input_text):\n",
    "    out_list = []\n",
    "    if not pd.isnull(input_text):\n",
    "        doc = nlp(input_text)\n",
    "        spans = list(doc.ents)  #+ list(doc.noun_chunks)\n",
    "\n",
    "        for item in spans:\n",
    "            try:\n",
    "                item = re.sub(pattern='[^a-zA-Z0-9 -]',repl='',string=item.string)            \n",
    "                if (re.search(item,name,flags=re.IGNORECASE)):\n",
    "                    out_list.append(item)\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    return out_list\n",
    "#     else:\n",
    "#         return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def basic_wc(input_text):\n",
    "    if not (pd.isnull(input_text)):\n",
    "        sent = re.sub(pattern='[^a-zA-Z0-9 -]',repl='',string=input_text)            \n",
    "        doc = nlp(sent)\n",
    "        return doc.__len__()\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_quarter(input_text):\n",
    "#     print(input_text)\n",
    "    try:                \n",
    "#         print(pd.isnull(input_text))\n",
    "        if not (pd.isnull(input_text)):\n",
    "            input_text = re.search('^.*\\((q[1-4]),.*', input_text, re.IGNORECASE)\n",
    "#             print(input_text,'##')\n",
    "            return input_text.group(1).strip()\n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "def split_year(input_text):\n",
    "    try:                \n",
    "        if not (pd.isnull(input_text)):\n",
    "            input_text = re.search(', ([0-9]+)\\)', input_text, re.IGNORECASE)\n",
    "            return input_text.group(1).strip()\n",
    "        return None\n",
    "    except:\n",
    "        return None    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE\tANALYST_Flag\tFIRM\tQuarter\tYear\n",
      "80853\n"
     ]
    }
   ],
   "source": [
    "# collection = \"html\"\n",
    "# data_folder = Path(collection)\n",
    "output_folder = PureWindowsPath('C:/Users/T.Santos18/Documents/workspace/textparsing/analyst')\n",
    "meta_folder = PureWindowsPath('C:/Users/T.Santos18/Documents/workspace/textparsing/meta')\n",
    "input_folder = PureWindowsPath('C:/Users/T.Santos18/Documents/workspace/textparsing/extract')\n",
    "\n",
    "n_test=10\n",
    "file_list = os.listdir(input_folder)\n",
    "out_list =[]\n",
    "# for i in range(len(file_list)):\n",
    "print('FILE\\tANALYST_Flag\\tFIRM\\tQuarter\\tYear') \n",
    "print(len(file_list))\n",
    "# for i in range(n_test):\n",
    "for i in range(len(file_list)):\n",
    "    if(re.search('csv',file_list[i],flags=re.IGNORECASE)):\n",
    "        out_list.append(file_list[i])\n",
    "#             print(file_list[i])\n",
    "\n",
    "out_pd = pd.DataFrame(out_list,columns=['file'])\n",
    "out_pd.to_csv(meta_folder / 'analyst_file_list.csv',sep=',',encoding='utf-8',index_label='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_csv = pd.read_csv(meta_folder / 'analyst_file_list.csv',index_col='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'analyst_out_foringestion_10.csv'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_csv.at[0,'file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ##success\n",
      "1 ##success\n",
      "2 ##success\n",
      "3 ##success\n",
      "4 ##success\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "fieldnames = ['index','fname', 'status']\n",
    "\n",
    "# with open('/Users/lky/workspace/convoparse/textparsing/log_ner_analyst_rerun.csv', 'w') as csvfile:\n",
    "with open(meta_folder / 'log_analyst_repeat.csv', 'w') as csvfile:\n",
    "    logwriter = csv.writer(csvfile,delimiter=',',quotechar='\"',quoting=csv.QUOTE_MINIMAL)\n",
    "#     logwriter.writerow(fieldnames)\n",
    "\n",
    "    for ii in range(0,20000):\n",
    "        try:\n",
    "            # out_analyst= pd.read_csv('analyst_out_foringestion.csv',encoding='utf-8',na_values='NaN')\n",
    "#             filename = '/Volumes/S/convoparse/extract/analyst_out_foringestion_' + str(ii)+'.csv' \n",
    "#             filename = '/Volumes/Transcend/extract/analyst_out_foringestion_' + str(ii)+'.csv' \n",
    "            filename = file_csv.at[ii,'file']\n",
    "\n",
    "            #         extract/analyst_out_foringestion_'+str(ii)+'.csv' \n",
    "#             fileout = '/Users/lky/workspace/convoparse/textparsing/test/analyst_out_foringestion_'+str(ii)+'.csv' \n",
    "            fileout = 'withcount_' + file_csv.at[ii,'file']\n",
    "\n",
    "#             out_analyst= pd.read_csv(filename,encoding='utf-8',na_values='NaN',header=None,\\\n",
    "            out_analyst= pd.read_csv(input_folder / filename,encoding='utf-8',na_values='NaN',header=None,\\\n",
    "                                     names=['index','file','quarter_year','executive_firm','ticker','analyst_name',\\\n",
    "                                           'analyst_firm','analyst_content','analyst_qanda','exec_name','exec_title'])\n",
    "    #         print(out_analyst)\n",
    "            out_analyst['quarter'] = out_analyst.apply(lambda x: \\\n",
    "                                                     split_quarter(x['quarter_year']), axis=1)\n",
    "\n",
    "            out_analyst['year'] = out_analyst.apply(lambda x: \\\n",
    "                                                     split_year(x['quarter_year']), axis=1)\n",
    "\n",
    "            out_analyst['exec_mention_qna'] = out_analyst.apply(lambda x: extract_name_pair(x['exec_name'],x['analyst_qanda']), axis=1)\n",
    "            out_analyst['exec_mention_transcript'] = out_analyst.apply(lambda x: extract_name_pair(x['exec_name'],x['analyst_content']), axis=1)\n",
    "            out_analyst['exec_count_qna'] = out_analyst.apply(lambda x: \\\n",
    "                                                     len(x['exec_mention_qna']), axis=1)\n",
    "\n",
    "            out_analyst['exec_count_transcript'] = out_analyst.apply(lambda x: \\\n",
    "                                                     len(x['exec_mention_transcript']), axis=1)\n",
    "            out_analyst['exec_count_total']= out_analyst.exec_count_qna+out_analyst.exec_count_transcript\n",
    "            out_analyst['analyst_qna_count'] = out_analyst.apply(lambda x: \\\n",
    "                                                     basic_wc(x['analyst_qanda']), axis=1)\n",
    "            out_analyst['analyst_content_count'] = out_analyst.apply(lambda x: \\\n",
    "                                                     basic_wc(x['analyst_content']), axis=1)\n",
    "            out_analyst['analyst_total_wc'] = out_analyst['analyst_qna_count'] + out_analyst['analyst_content_count']\n",
    "\n",
    "            # out_analyst[['file','quarter_year','executive_firm','ticker',\\\n",
    "            # 'analyst_name','analyst_firm','analyst_total_wc','exec_name','exec_title','exec_mention_qna','exec_count_qna',\n",
    "            #             'exec_mention_transcript','exec_count_transcript','exec_count_total']]\\\n",
    "            # .to_csv('analyst_out_withcount.csv',sep=',', encoding = 'utf-8')\n",
    "            # out_executives.select({[}'file','quarter_yer'])\n",
    "\n",
    "            out_analyst[['file','quarter','year','executive_firm','ticker',\\\n",
    "            'analyst_name','analyst_firm','analyst_total_wc','exec_name','exec_title','exec_count_total']]\\\n",
    "            .to_csv(output_folder / fileout,sep=',', encoding = 'utf-8',header=False)\n",
    "#             .to_csv(fileout,sep=',', encoding = 'utf-8',header=False)\n",
    "        #     .to_csv('analyst_out_withcount.csv',sep=',', encoding = 'utf-8')    \n",
    "            logwriter.writerow([ii,fileout ,'success'])\n",
    "            print(ii,'##success')\n",
    "\n",
    "        except:\n",
    "            print(ii,'##fail')\n",
    "            logwriter.writerow([ii,fileout ,'fail'])\n",
    "            \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
