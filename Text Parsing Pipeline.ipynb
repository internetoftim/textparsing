{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "import en_core_web_sm\n",
    "import keras\n",
    "import tensorflow\n",
    "from pathlib import Path\n",
    "from pathlib import PureWindowsPath\n",
    "import helper_parsing_functions\n",
    "from helper_parsing_functions import *\n",
    "import csv\n",
    "from dateparser.search import search_dates\n",
    "import arrow\n",
    "import datetime\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "def extract_name_pair(name, input_text):\n",
    "    out_list = []\n",
    "    if not (input_text==[]):\n",
    "        #         s_out = extract_chunks(input_text)  \n",
    "        sent =  \" \".join(str(x) for x in input_text)\n",
    "        #     doc = nlp(input_text)\n",
    "        doc = nlp(sent)        \n",
    "        #         doc = nlp(input_text)\n",
    "        spans = list(doc.ents)  #+ list(doc.noun_chunks)\n",
    "\n",
    "        for item in spans:\n",
    "            try:\n",
    "                item = re.sub(pattern='[^a-zA-Z0-9 -]',repl='',string=item.string)            \n",
    "                if (re.search(item,name,flags=re.IGNORECASE)):\n",
    "                    out_list.append(item)\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "collection = \"html\"\n",
    "\n",
    "# n_test=50\n",
    "file_list = os.listdir(collection)\n",
    "# for i in range(len(file_list)):\n",
    "# for i in range(n_test):\n",
    "#     print(file_list[i])\n",
    "print(len(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE\tANALYST_Flag\tFIRM\tQuarter\tYear\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "collection = \"./html\"\n",
    "# data_folder = Path(collection)\n",
    "output_folder = PureWindowsPath('C:/Users/T.Santos18/Documents/workspace/textparsing/exec')\n",
    "# input_folder = PureWindowsPath('C:/Users/T.Santos18/Documents/workspace/textparsing/html')\n",
    "\n",
    "output_folder = Path('./output/')\n",
    "input_folder = Path(collection)\n",
    "\n",
    "\n",
    "n_test=1\n",
    "file_list = os.listdir(collection)\n",
    "out_list =[]\n",
    "# for i in range(len(file_list)):\n",
    "print('FILE\\tANALYST_Flag\\tFIRM\\tQuarter\\tYear') \n",
    "print(len(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-134-47003571f59b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-134-47003571f59b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    contents = open(str( / file_list[i]), \"r\").read()\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "contents = open(str( / file_list[i]), \"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5717.html\n"
     ]
    }
   ],
   "source": [
    "out_list = []\n",
    "for i in range(len(file_list)):\n",
    "    if(re.search('html',file_list[i],flags=re.IGNORECASE)):\n",
    "        out_list.append(file_list[i])\n",
    "        print(file_list[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_file = pd.DataFrame(out_list,columns=['filename'])\n",
    "out_file.index.names=['index']\n",
    "out_file.to_csv('all_html.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_file.iloc[0]['filename']\n",
    "len(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_folder = Path('./sample_out')\n",
    "input_folder = Path(collection)\n",
    "# print(input_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('sample_out')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f\n"
     ]
    }
   ],
   "source": [
    "display(output_folder)\n",
    "with open(str( output_folder/'test_extract.csv'), \"w+\") as csvfile:\n",
    "    print('f')\n",
    "    logwriter = csv.writer(csvfile,delimiter='\\t',quotechar='\"',quoting=csv.QUOTE_MINIMAL)\n",
    "    logwriter.writerow(['1','1','fail'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ii = 0\n",
    "test =[out_file.iloc[0].filename]\n",
    "test\n",
    "test = pd.DataFrame(test,columns=['filename'])\n",
    "test\n",
    "type(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "here\n"
     ]
    }
   ],
   "source": [
    "output_folder = Path('./sample_out')\n",
    "\n",
    "with open(str(output_folder / 'test_extract.csv'), \"w+\") as csvfile:\n",
    "\n",
    "    logwriter = csv.writer(csvfile,delimiter='\\t',quotechar='\"',quoting=csv.QUOTE_MINIMAL)\n",
    "    i_start = 0\n",
    "    i_end = 1\n",
    " \n",
    "    for ii in range(i_start,i_end):\n",
    "        try:\n",
    "            #batch\n",
    "            #basically 1 file at a time now\n",
    "            row_start = ii*1\n",
    "            row_end = (ii*1)+1\n",
    "            filename = input_folder /  out_file.iloc[0]['filename']\n",
    "\n",
    "            output_filename = 'out_' + str(ii) + '.csv'\n",
    "            output_filename_exec = 'out_exec_' + str(ii) + '.csv'\n",
    "            output_filename_analyst = 'out_analyst_' + str(ii) + '.csv'\n",
    "\n",
    "#             for i in range(row_start,row_end):\n",
    "#                 out_list.append(file_list[i])\n",
    "            contents = extract_html(str(filename))\n",
    "            print('here')\n",
    "            out_pd = out_file\n",
    "            out_pd['text'] = out_pd.apply(lambda x: extract_html(str(input_folder / x['filename'])), axis=1)\n",
    "            out_pd['quarter'] = out_pd.apply(lambda x: extract_quarter(x['text']), axis=1)\n",
    "            out_pd['call_date'] = out_pd.apply(lambda x: extract_time(x['text']), axis=1)\n",
    "            out_pd['year'] = out_pd.apply(lambda x: extract_year(x['text']), axis=1)\n",
    "            out_pd['executive_firm'] = out_pd.apply(lambda x: extract_firm(x['text']), axis=1)\n",
    "            out_pd['ticker'] = out_pd.apply(lambda x: extract_ticker(x['text']), axis=1)\n",
    "            out_pd['analysts'] = out_pd.apply(lambda x: extract_analysts(x['text']), axis=1)\n",
    "            out_pd['execs'] = out_pd.apply(lambda x: extract_executives(x['text']), axis=1)\n",
    "            \n",
    "            s = out_pd.execs.apply(pd.Series)\\\n",
    "                          .stack()\\\n",
    "                          .reset_index(level=1, drop=True)\\\n",
    "                          .to_frame('executives')\n",
    "            out_executives = out_pd.join(s)                      \n",
    "            \n",
    "\n",
    "\n",
    "            \n",
    "            out_executives['exec_name'] = out_executives.apply(lambda x: extract_name(x['executives']), axis=1)\n",
    "            out_executives['exec_title'] = out_executives.apply(lambda x: extract_title(x['executives']), axis=1)\n",
    "#             out_pd = out_pd.drop(['text'],axis=1)\n",
    "\n",
    "            out_executives['executive_content'] = out_executives.apply(lambda x: \\\n",
    "                                                     extract_content(contents,x['exec_name']), axis=1)\n",
    "            out_executives['executive_qanda'] = out_executives.apply(lambda x: \\\n",
    "                                                     extract_qanda(contents,x['exec_name']), axis=1)\n",
    "            out_executives=out_executives.reset_index(level=0, drop=True)\n",
    "            \n",
    "            s = out_executives.execs.apply(pd.Series)\\\n",
    "                          .stack()\\\n",
    "                          .reset_index(level=1, drop=True)\\\n",
    "                          .to_frame('mention')\n",
    "            out_executives = out_executives.join(s)    \n",
    "            \n",
    "            out_executives['mention_name'] = out_executives.apply(lambda x: extract_name(x['mention']), axis=1)\n",
    "            \n",
    "            out_executives['mention_title'] = out_executives.apply(lambda x: extract_title(x['mention_name']), axis=1)\n",
    "            \n",
    "            out_executives['exec_mention_qna'] = out_executives.apply(lambda x: extract_name_pair(x['mention_name'],x['executive_qanda']), axis=1)\n",
    "            \n",
    "            out_executives['exec_mention_transcript'] = out_executives.apply(lambda x: extract_name_pair(x['mention_name'],x['executive_content']), axis=1)\n",
    "     \n",
    "        \n",
    "        \n",
    "\n",
    "            s = out_pd.analysts.apply(pd.Series)\\\n",
    "                          .stack()\\\n",
    "                          .reset_index(level=1, drop=True)\\\n",
    "                          .to_frame('analyst')\n",
    "            out_analysts = out_pd.join(s)                 \n",
    "            \n",
    "            \n",
    "            out_analysts['analyst_name'] = out_analysts.apply(lambda x: extract_name(x['analyst']), axis=1)\n",
    "            out_analysts['analyst_firm'] = out_analysts.apply(lambda x: extract_title(x['analyst']), axis=1)\n",
    "\n",
    "            out_analysts['analyst_content'] = out_analysts.apply(lambda x: \\\n",
    "                                                     extract_content(contents,x['analyst_name']), axis=1)\n",
    "            \n",
    "            out_analysts['analyst_qanda'] = out_analysts.apply(lambda x: \\\n",
    "                                                     extract_qanda(contents,x['analyst_name']), axis=1)\n",
    "\n",
    "            out_analysts=out_analysts.reset_index(level=0, drop=True)\n",
    "\n",
    "            s = out_analysts.execs.apply(pd.Series)\\\n",
    "                          .stack()\\\n",
    "                          .reset_index(level=1, drop=True)\\\n",
    "                          .to_frame('mention')\n",
    "            out_analysts = out_analysts.join(s)                 \n",
    "            out_analysts['mention_name'] = out_analysts.apply(lambda x: extract_name(x['mention']), axis=1)\n",
    "            out_analysts['mention_title'] = out_analysts.apply(lambda x: extract_title(x['mention']), axis=1)\n",
    "            \n",
    "            out_analysts['exec_mention_qna'] = out_analysts.apply(lambda x: extract_name_pair(x['mention_name'],x['analyst_qanda']), axis=1)\n",
    "            out_analysts['exec_mention_transcript'] = out_analysts.apply(lambda x: extract_name_pair(x['mention_name'],x['analyst_content']), axis=1)\n",
    "            \n",
    "            \n",
    "#             out_executives['exec_qna_count'] = out_executives.apply(lambda x: \\\n",
    "#                                                      basic_wc(x['executive_qanda']), axis=1)\n",
    "\n",
    "#             out_executives['exec_content_count'] = out_executives.apply(lambda x: \\\n",
    "#                                                      basic_wc(x['executive_content']), axis=1)\n",
    "#             out_executives['exec_total_count'] = out_executives.exec_qna_count + out_executives.exec_content_count\n",
    "\n",
    "#             out_pd=out_pd.reset_index(level=0, drop=True)\n",
    "#             # out_analyst\n",
    "#             s = out_pd.execs.apply(pd.Series)\\\n",
    "#                           .stack()\\\n",
    "#                           .reset_index(level=1, drop=True)\\\n",
    "#                           .to_frame('mention_name')\n",
    "#             out_pd = out_pd.join(s)                      \n",
    "                        \n",
    "#             out_executives = out_executives.join(s)          \n",
    "#             out_executives['mention_titile'] = out_executives.apply(lambda x: extract_title(x['mention_name']), axis=1)\n",
    "#             out_executives['mention_name'] = out_executives.apply(lambda x: extract_name(x['mention_name']), axis=1)\n",
    "#             out_executives['exec_mention_qna'] = out_executives.apply(lambda x: extract_name_pair(x['mention_name'],x['executive_qanda']), axis=1)\n",
    "#             out_executives['exec_mention_transcript'] = out_executives.apply(lambda x: extract_name_pair(x['mention_name'],x['executive_content']), axis=1)\n",
    "#             out_executives['mention_name_count_qna'] = out_executives.apply(lambda x: \\\n",
    "#                                           len(x['exec_mention_qna']), axis=1)\n",
    "#             out_executives['mention_name_count_transcript'] = out_executives.apply(lambda x: \\\n",
    "#                                           len(x['exec_mention_transcript']), axis=1)\n",
    "#             out_executives['mention_name_count_total']= out_executives.mention_name_count_qna+out_executives.mention_name_count_transcript\n",
    "# #             print('here##')\n",
    "#             # out_analyst.drop(['text','analyst_present','analysts','executive'],axis=1)\n",
    "#             out_executives.drop(['text','executive','execs','exec_mention_qna',\\\n",
    "#                                  'exec_mention_transcript'],axis=1)\\\n",
    "#             .to_csv(output_folder / filename,sep=',', encoding = 'utf-8',header=False)\n",
    "           \n",
    "#         #             .to_csv(filename,sep=',', encoding = 'utf-8',header=False)\n",
    "#             # out_executives.select({[}'file','quarter_yer'])    \n",
    "# #             print('success: ', ii, ' ###')\n",
    "#             logwriter.writerow([ii,out_executives.file.head(1).item(),'success'])\n",
    "            out_pd \\\n",
    "    .to_csv(output_folder / output_filename,sep=',', encoding = 'utf-8',header=True)\n",
    "            \n",
    "#             out_executives \\\n",
    "#     .to_csv(output_folder / output_filename_exec,sep=',', encoding = 'utf-8',header=True)    \n",
    "    \n",
    "            out_executives \\\n",
    "    .drop(['text','executive_content','executive_qanda'],axis=1) \\\n",
    "    .to_csv(output_folder / output_filename_exec,sep=',', encoding = 'utf-8',header=True)    \n",
    "            \n",
    "#             out_analysts \\\n",
    "#     .to_csv(output_folder / output_filename_analyst,sep=',', encoding = 'utf-8',header=True)\n",
    "    \n",
    "            out_analysts \\\n",
    "    .drop(['text','analyst_content','analyst_qanda'],axis=1) \\\n",
    "    .to_csv(output_folder / output_filename_analyst,sep=',', encoding = 'utf-8',header=True)    \n",
    "            print('here')\n",
    "        except:\n",
    "            print('exception: ', ii, ' ###')\n",
    "#             logwriter.writerow([ii,out_executives.file.head(1).item(),'fail'])\n",
    "            \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_time(input_soup):\n",
    "    temp = input_soup.find(id='article_participants')\n",
    "    for element in temp.find_all('p'):\n",
    "        temp_string=element.text.strip()\n",
    "        \n",
    "        try:\n",
    "#             December 2, 2014 11:15 AM ET\n",
    "            \n",
    "            temp_string = re.match(string=temp_string,pattern=\\\n",
    "                                   '^[^a-zA-Z]*([a-zA-Z]+\\s+[0-9]+,\\s+[0-9]{4})[^ 0-9]?(\\s+[0-9]{1,2}:[0-9]{2}\\s+[APap]\\.?[mM]\\.?).*')\n",
    "            string1 = temp_string.group(1)\n",
    "            string2 = temp_string.group(2)\n",
    "            #         name_search.group(1).strip()\n",
    "            string3 = string1 + string2\n",
    "            string3 = re.sub(string=string3,pattern='\\.',repl='')\n",
    "            string3 = re.sub(string=string3,pattern='\\s+',repl=' ')\n",
    "#             print(string1,'##',string2,'##',string3)\n",
    "            date_out = arrow.get(string3,'MMMM D, YYYY H:mm A')\n",
    "        except:\n",
    "            date_out=None        \n",
    "            \n",
    "        if date_out is not None:\n",
    "            return date_out.isoformat()\n",
    "    temp = input_soup.find(id='article_content')\n",
    "    \n",
    "    for element in temp.find_all('a'):\n",
    "        temp_string=element.text.strip()\n",
    "        temp_string = re.sub(string=temp_string,pattern='\\s+',repl=' ')\n",
    "        try:\n",
    "            while  (element):\n",
    "                try:\n",
    "                    date_out = arrow.get(temp_string,'MMMM D, YYYY H:mm A')\n",
    "                except:\n",
    "                    date_out=None       \n",
    "                if date_out is not None:\n",
    "    #                 return temp_string\n",
    "                    return date_out.isoformat()\n",
    "\n",
    "\n",
    "                element = element.next_sibling\n",
    "                temp_string = element\n",
    "                temp_string = re.sub(string=temp_string,pattern='\\s+',repl=' ')  \n",
    "    #             print(temp_string.find('div'))\n",
    "    #             print(temp_string.find('strong'))\n",
    "        except:\n",
    "            pass\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_quarter(input_soup):\n",
    "    \n",
    "    try:\n",
    "        temp = input_soup.find(id='article_participants')\n",
    "        for element in temp.findAll('p'):\n",
    "            if (pd.notnull(element.text) and element.text!=''):\n",
    "                if( re.search('q[1-4]\\s*[0-9]{4}',element.contents[0],flags=re.IGNORECASE)):\n",
    "                    print(element.contents[0])\n",
    "                    temp_string = re.match(string=element.contents[0],\\\n",
    "                                           pattern='[^qQ]*([qQ][1-4])\\s*[0-9]{4}.*')\n",
    "                    print(temp_string.group(1))\n",
    "                    call_title = element.contents[0].split()\n",
    "                    return temp_string.group(1)\n",
    "                \n",
    "        temp = input_soup.find(id='article_source')        \n",
    "        for element in temp.findAll('a'):\n",
    "            if (pd.notnull(element.text) and element.text!=''):\n",
    "                if( re.search('q[1-4]\\s*[0-9]{4}',element.contents[0],flags=re.IGNORECASE)):\n",
    "                    print(element.contents[0])\n",
    "                    temp_string = re.match(string=element.contents[0],\\\n",
    "                                           pattern='[^qQ]*([qQ][1-4])\\s*[0-9]{4}.*')\n",
    "                    print(temp_string.group(1))\n",
    "                    call_title = element.contents[0].split()\n",
    "                    return temp_string.group(1)                \n",
    "        return None\n",
    "    except:\n",
    "\n",
    "        return None\n",
    "    \n",
    "def extract_year(input_soup):\n",
    "    \n",
    "    try:\n",
    "        temp = input_soup.find(id='article_participants')\n",
    "        for element in temp.findAll('p'):\n",
    "            if (pd.notnull(element.text) and element.text!=''):\n",
    "                if( re.search('q[1-4]\\s*[0-9]{4}',element.contents[0],flags=re.IGNORECASE)):\n",
    "                    print(element.contents[0])\n",
    "                    temp_string = re.match(string=element.contents[0],\\\n",
    "                                           pattern='[^qQ]*[qQ][1-4]\\s*([0-9]{4}).*')\n",
    "                    print(temp_string.group(1))\n",
    "                    call_title = element.contents[0].split()\n",
    "                    return temp_string.group(1)\n",
    "                \n",
    "        temp = input_soup.find(id='article_source')        \n",
    "        for element in temp.findAll('a'):\n",
    "            if (pd.notnull(element.text) and element.text!=''):\n",
    "                if( re.search('q[1-4]\\s*[0-9]{4}',element.contents[0],flags=re.IGNORECASE)):\n",
    "                    print(element.contents[0])\n",
    "                    temp_string = re.match(string=element.contents[0],\\\n",
    "                                           pattern='[^qQ]*[qQ][1-4]\\s*([0-9]{4}).*')\n",
    "                    print(temp_string.group(1))\n",
    "                    call_title = element.contents[0].split()\n",
    "                    return temp_string.group(1)                \n",
    "        return None\n",
    "    except:\n",
    "        return None  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Some Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "fieldnames = ['index','fname', 'status']\n",
    "# output_folder = PureWindowsPath('C:/Users/T.Santos18/Documents/workspace/textparsing/exec')\n",
    "output_folder = PureWindowsPath('C:/Users/T.Santos18/Documents/workspace/textparsing/dates')\n",
    "input_folder = PureWindowsPath('C:/Users/T.Santos18/Documents/workspace/textparsing/html')\n",
    "\n",
    "\n",
    "with open(output_folder / 'log_extract.csv', 'w') as csvfile:\n",
    "\n",
    "    logwriter = csv.writer(csvfile,delimiter='\\t',quotechar='\"',quoting=csv.QUOTE_MINIMAL)\n",
    "    for ii in range(1,10):\n",
    "        try:\n",
    "            total_rows = len(file_list)\n",
    "            row_start = ii*1\n",
    "            row_end = (ii*1)+1\n",
    "            filename = 'exec_out_foringestion_'+str(row_start)+'.csv'\n",
    "\n",
    "            out_list =[]\n",
    "\n",
    "            for i in range(row_start,row_end):\n",
    "                with open(input_folder / file_list[i]) as inf:\n",
    "#                 with open(collection + '/' + file_list[i]) as inf:\n",
    "                    if(re.search('html',file_list[i],flags=re.IGNORECASE)):\n",
    "                        out_list.append(file_list[i])\n",
    "\n",
    "            out_pd = pd.DataFrame(out_list)\n",
    "            out_pd.columns=['file']\n",
    "            out_pd['text'] = out_pd.apply(lambda x: extract_html('html/'+x['file']), axis=1)\n",
    "            out_pd['quarter'] = out_pd.apply(lambda x: extract_quarter(x['text']), axis=1)\n",
    "            out_pd['year'] = out_pd.apply(lambda x: extract_year(x['text']), axis=1)\n",
    "            out_pd['executive_firm'] = out_pd.apply(lambda x: extract_firm(x['text']), axis=1)\n",
    "            out_pd['ticker'] = out_pd.apply(lambda x: extract_ticker(x['text']), axis=1)\n",
    "            \n",
    "            out_executives = out_pd                      \n",
    "            out_executives.drop(['text'],axis=1).to_csv(output_folder / filename,sep=',', encoding = 'utf-8',header=False)\n",
    "            logwriter.writerow([ii,out_executives.file.head(1).item(),'success'])\n",
    "        except:\n",
    "            print('exception: ', ii, ' ###')\n",
    "            logwriter.writerow([ii,out_executives.file.head(1).item(),'fail'])\n",
    "            \n",
    "            pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
