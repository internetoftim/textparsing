{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "import en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_html(input_html):\n",
    "    with open(input_html) as inf:\n",
    "        txt = inf.read()\n",
    "    soup_out = soup(txt, \"html.parser\")\n",
    "    print(input_html)\n",
    "    return soup_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_firm(input_soup):\n",
    "    temp = input_soup.find(id='article_participants')\n",
    "    for element in temp.findAll('a'):\n",
    "        if element.get('title') != None :\n",
    "            return(str(element.get('title')))   \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_ticker(input_soup):\n",
    "    temp = input_soup.find(id='article_participants')\n",
    "    for element in temp.findAll('a'):\n",
    "        if element.get('title') != None :\n",
    "            return(str(element.contents[0].strip()))   \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_time(input_soup):\n",
    "    temp = input_soup.find(id='article_participants')\n",
    "    try:\n",
    "        for element in temp.findAll('p'):\n",
    "            if (pd.notnull(element.text) and element.text!=''):\n",
    "                if( re.search('call',element.contents[0],flags=re.IGNORECASE)):\n",
    "                    call_title = element.contents[0].split()\n",
    "                    return str(call_title[0]),str(call_title[1])\n",
    "        return None,None\n",
    "    except:\n",
    "        return None,None\n",
    "    \n",
    "def extract_quarter(input_soup):\n",
    "    temp = input_soup.find(id='article_participants')\n",
    "    try:\n",
    "        for element in temp.findAll('p'):\n",
    "            if (pd.notnull(element.text) and element.text!=''):\n",
    "                if( re.search('call',element.contents[0],flags=re.IGNORECASE)):\n",
    "                    call_title = element.contents[0].split()\n",
    "                    return str(call_title[0])\n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def extract_year(input_soup):\n",
    "    temp = input_soup.find(id='article_participants')\n",
    "    try:\n",
    "        for element in temp.findAll('p'):\n",
    "            if (pd.notnull(element.text) and element.text!=''):\n",
    "                if( re.search('call',element.contents[0],flags=re.IGNORECASE)):\n",
    "                    call_title = element.contents[0].split()\n",
    "                    return str(call_title[1])\n",
    "        return None\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_analyst(input_soup):\n",
    "    temp = input_soup.find(id='article_participants')\n",
    "    for element in temp.findAll('strong'):\n",
    "        if(re.search('analyst',element.contents[0],flags=re.IGNORECASE)):\n",
    "            return(True)\n",
    "    return(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_analysts(input_soup):\n",
    "    temp = input_soup.find(id='article_participants')\n",
    "    test_string = []\n",
    "    print_flag = False\n",
    "    for element in temp.find_all('p'):\n",
    "        if(re.search('analyst',element.text,flags=re.IGNORECASE)):\n",
    "            #print(element.text.strip(),'###')\n",
    "            element = element.find_next()\n",
    "            while  (1):\n",
    "                element = element.find_next()\n",
    "            #print(element.contents[0].strip())\n",
    "            #print(element.text.strip())\n",
    "                if element.find('strong') or \\\n",
    "                element.find('div'):\n",
    "            #print('FOUND')\n",
    "                    break\n",
    "                if (pd.notnull(element.text) and element.text!=''):\n",
    "                    test_string.append(element.contents[0].strip())    \n",
    "            break\n",
    "    return test_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_executives(input_soup):\n",
    "    test_string = []\n",
    "    temp = input_soup.find(id='article_participants')\n",
    "    # print(soup_out)\n",
    "    print_flag = False\n",
    "    for element in temp.find_all('p'):\n",
    "        if(re.search('executive',element.text,flags=re.IGNORECASE)):\n",
    "            #print(element.text.strip(),'###')\n",
    "            element = element.find_next()\n",
    "            while  (1):\n",
    "                element = element.find_next()\n",
    "                # print(element.contents[0])\n",
    "                # print(element.text.strip())\n",
    "                if element.find('strong') or \\\n",
    "                element.find('div'):            \n",
    "                #print('FOUND')\n",
    "                    break\n",
    "                test_string.append(element.text.strip())\n",
    "        \n",
    "            break\n",
    "    return test_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_analyst_present(analyst_list):\n",
    "    if analyst_list: \n",
    "        return True\n",
    "    else: \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_name (input_string,delim='-'):\n",
    "    if not pd.isnull(input_string):\n",
    "        name_search = re.search('(^[^-]*)-', input_string, re.IGNORECASE)\n",
    "        try:\n",
    "            return name_search.group(1).strip()\n",
    "        except:\n",
    "            return None        \n",
    "    else:\n",
    "        return None\n",
    "def extract_title (input_string,delim='-'):\n",
    "    if not pd.isnull(input_string):\n",
    "        title_search = re.search('^[^-]*-(.*)', input_string, re.IGNORECASE)\n",
    "        try:\n",
    "            return title_search.group(1).strip()\n",
    "        except:\n",
    "            return None           \n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_content(input_soup,current_name):\n",
    "#     current_name = 'Panna Sharma'\n",
    "    if not (pd.isnull(current_name) ):\n",
    "        temp = input_soup.find(id='article_content')\n",
    "        test_string = []\n",
    "        # print(temp)\n",
    "        for element in temp.find_all('strong'):\n",
    "            if (re.search(current_name.strip().lower(),element.text,flags=re.IGNORECASE)):\n",
    "                while  (1):\n",
    "                    element = element.find_next()\n",
    "        #           print(element.text.strip())\n",
    "                    if element.find('strong') or \\\n",
    "                    element.find('div'):\n",
    "                        break\n",
    "                    test_string.append(element.text.strip())    \n",
    "        return test_string\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_qanda(input_soup,current_name):\n",
    "#     current_name = 'Panna Sharma'\n",
    "    if not (pd.isnull(current_name) ):\n",
    "        temp = input_soup.find(id='article_qanda')\n",
    "        test_string = []\n",
    "        # print(temp)\n",
    "        if temp.find_all('span'):\n",
    "            for element in temp.find_all('span'):\n",
    "                if (re.search(current_name.strip().lower(),element.text,flags=re.IGNORECASE)):\n",
    "                    while  (1):\n",
    "                        element = element.find_next()\n",
    "            #           print(element.text.strip())\n",
    "                        if element.find('strong') or \\\n",
    "                        element.find('div') or \\\n",
    "                        element.find('span'):\n",
    "                            break\n",
    "                        test_string.append(element.text.strip())    \n",
    "        else:                \n",
    "            for element in temp.find_all('strong'):\n",
    "                if (re.search(current_name.strip().lower(),element.text,flags=re.IGNORECASE)):\n",
    "                    while  (1):\n",
    "                        element = element.find_next()\n",
    "            #           print(element.text.strip())\n",
    "                        if element.find('strong') or \\\n",
    "                        element.find('div') or \\\n",
    "                        element.find('span'):\n",
    "                            break\n",
    "                        test_string.append(element.text.strip())      \n",
    "            \n",
    "        return test_string\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "def basic_wc(input_text):\n",
    "    if not (input_text==[]):\n",
    "#         decoded_txt=input_text.decode('utf-8')\n",
    "        sent =  \" \".join(str(x) for x in input_text)\n",
    "        sent = re.sub(pattern='[^a-zA-Z0-9 -]',repl='',string=sent)            \n",
    "        doc = nlp(sent)\n",
    "        return doc.__len__()\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_chunks(input_text):\n",
    "    sent =  \" \".join(str(x) for x in input_text)\n",
    "    #     doc = nlp(input_text)\n",
    "    doc = nlp(sent)\n",
    "    spans = list(doc.ents)  #+ list(doc.noun_chunks)\n",
    "    out_list = []\n",
    "    for span in spans:\n",
    "        span.merge()\n",
    "        out_list.append(span)\n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_name_pair(name, input_text):\n",
    "    out_list = []\n",
    "    if not (input_text==[]):\n",
    "#         s_out = extract_chunks(input_text)  \n",
    "        sent =  \" \".join(str(x) for x in input_text)\n",
    "        #     doc = nlp(input_text)\n",
    "        doc = nlp(sent)        \n",
    "#         doc = nlp(input_text)\n",
    "        spans = list(doc.ents)  #+ list(doc.noun_chunks)\n",
    "\n",
    "        for item in spans:\n",
    "            try:\n",
    "                item = re.sub(pattern='[^a-zA-Z0-9 -]',repl='',string=item.string)            \n",
    "                if (re.search(item,name,flags=re.IGNORECASE)):\n",
    "                    out_list.append(item)\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    return out_list\n",
    "#     else:\n",
    "#         return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91979\n"
     ]
    }
   ],
   "source": [
    "collection = \"html\"\n",
    "\n",
    "# n_test=50\n",
    "file_list = os.listdir(collection)\n",
    "# for i in range(len(file_list)):\n",
    "# for i in range(n_test):\n",
    "#     print(file_list[i])\n",
    "print(len(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE\tANALYST_Flag\tFIRM\tQuarter\tYear\n"
     ]
    }
   ],
   "source": [
    "collection = \"html\"\n",
    "\n",
    "n_test=4\n",
    "file_list = os.listdir(collection)\n",
    "out_list =[]\n",
    "# for i in range(len(file_list)):\n",
    "print('FILE\\tANALYST_Flag\\tFIRM\\tQuarter\\tYear') \n",
    "\n",
    "for i in range(n_test):\n",
    "    with open(collection + '/' + file_list[i]) as inf:\n",
    "        if(re.search('html',file_list[i],flags=re.IGNORECASE)):\n",
    "            out_list.append(file_list[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "html/1.html\n",
      "html/10.html\n",
      "html/100.html\n"
     ]
    }
   ],
   "source": [
    "out_pd = pd.DataFrame(out_list)\n",
    "out_pd.columns=['file']\n",
    "out_pd['text'] = out_pd.apply(lambda x: extract_html('html/'+x['file']), axis=1)\n",
    "out_pd['quarter'] = out_pd.apply(lambda x: extract_quarter(x['text']), axis=1)\n",
    "out_pd['year'] = out_pd.apply(lambda x: extract_year(x['text']), axis=1)\n",
    "# out_pd['quarter_year'] = out_pd.apply(lambda x: extract_q(x['text']), axis=1)\n",
    "out_pd['executive_firm'] = out_pd.apply(lambda x: extract_firm(x['text']), axis=1)\n",
    "out_pd['analyst_present'] = out_pd.apply(lambda x: test_analyst(x['text']), axis=1)\n",
    "out_pd['ticker'] = out_pd.apply(lambda x: extract_ticker(x['text']), axis=1)\n",
    "\n",
    "out_pd['analysts'] = out_pd.apply(lambda x: extract_analysts(x['text']), axis=1)\n",
    "out_pd['execs'] = out_pd.apply(lambda x: extract_executives(x['text']), axis=1)\n",
    "\n",
    "s = out_pd.execs.apply(pd.Series)\\\n",
    "              .stack()\\\n",
    "              .reset_index(level=1, drop=True)\\\n",
    "              .to_frame('executive')\n",
    "out_executives = out_pd.join(s)                      \n",
    "\n",
    "\n",
    "out_executives['exec_name'] = out_executives.apply(lambda x: extract_name(x['executive']), axis=1)\n",
    "out_executives['exec_title'] = out_executives.apply(lambda x: extract_title(x['executive']), axis=1)\n",
    "\n",
    "out_executives['executive_content'] = out_executives.apply(lambda x: \\\n",
    "                                         extract_content(x['text'],x['exec_name']), axis=1)\n",
    "out_executives['executive_qanda'] = out_executives.apply(lambda x: \\\n",
    "                                         extract_qanda(x['text'],x['exec_name']), axis=1)\n",
    "\n",
    "out_executives['exec_qna_count'] = out_executives.apply(lambda x: \\\n",
    "                                         basic_wc(x['executive_qanda']), axis=1)\n",
    "\n",
    "out_executives['exec_content_count'] = out_executives.apply(lambda x: \\\n",
    "                                         basic_wc(x['executive_content']), axis=1)\n",
    "out_executives['exec_total_count'] = out_executives.exec_qna_count + out_executives.exec_content_count\n",
    "\n",
    "out_executives=out_executives.reset_index(level=0, drop=True)\n",
    "# out_analyst\n",
    "s = out_executives.execs.apply(pd.Series)\\\n",
    "              .stack()\\\n",
    "              .reset_index(level=1, drop=True)\\\n",
    "              .to_frame('mention_name')\n",
    "out_executives = out_executives.join(s)          \n",
    "out_executives['mention_name'] = out_executives.apply(lambda x: extract_name(x['mention_name']), axis=1)\n",
    "\n",
    "out_executives['exec_mention_qna'] = out_executives.apply(lambda x: extract_name_pair(x['mention_name'],x['executive_qanda']), axis=1)\n",
    "out_executives['exec_mention_transcript'] = out_executives.apply(lambda x: extract_name_pair(x['mention_name'],x['executive_content']), axis=1)\n",
    "out_executives['exec_count_qna'] = out_executives.apply(lambda x: \\\n",
    "                              len(x['exec_mention_qna']), axis=1)\n",
    "out_executives['exec_count_transcript'] = out_executives.apply(lambda x: \\\n",
    "                              len(x['exec_mention_transcript']), axis=1)\n",
    "out_executives['exec_count_total']= out_executives.exec_count_qna+out_executives.exec_count_transcript\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_analyst.drop(['text','analyst_present','analysts','executive'],axis=1)\n",
    "out_executives.drop(['text','executive','execs'],axis=1)\\\n",
    ".to_csv('analyst_out_foringestion.csv',sep=',', encoding = 'utf-8')\n",
    "# out_executives.select({[}'file','quarter_yer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "html/1.html\n",
      "html/10.html\n",
      "html/100.html\n",
      "html/1000.html\n",
      "html/10000.html\n",
      "html/10001.html\n",
      "html/10002.html\n",
      "exception:  7  ###\n",
      "html/10003.html\n",
      "html/10004.html\n",
      "html/10005.html\n",
      "html/10006.html\n",
      "html/10007.html\n",
      "html/10008.html\n",
      "html/10009.html\n",
      "html/1001.html\n",
      "html/10010.html\n",
      "exception:  16  ###\n",
      "html/10011.html\n",
      "html/10012.html\n",
      "html/10013.html\n",
      "exception:  19  ###\n",
      "html/10014.html\n",
      "html/10015.html\n",
      "exception:  21  ###\n",
      "html/10016.html\n",
      "html/10017.html\n",
      "html/10018.html\n",
      "html/10019.html\n",
      "html/1002.html\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "fieldnames = ['index','fname', 'status']\n",
    "\n",
    "with open('log_extract.csv', 'w') as csvfile:\n",
    "    logwriter = csv.writer(csvfile,delimiter='\\t',quotechar='\"',quoting=csv.QUOTE_MINIMAL)\n",
    "#     logwriter.writerow(fieldnames)\n",
    "\n",
    " \n",
    "    for ii in range(1,91980):\n",
    "#     for ii in range(1,4):\n",
    "        try:\n",
    "            total_rows = len(file_list)\n",
    "            row_start = ii*1\n",
    "            row_end = (ii*1)+1\n",
    "        #     print('from: ', row_start, ' to: ', row_end)\n",
    "            filename = 'exec/exec_out_foringestion_'+str(row_start)+'.csv'\n",
    "#             print('FILE\\tANALYST_Flag\\tFIRM\\tQuarter\\tYear') \n",
    "#             print(ii,'####')\n",
    "            out_list =[]\n",
    "\n",
    "            for i in range(row_start,row_end):\n",
    "                with open(collection + '/' + file_list[i]) as inf:\n",
    "                    if(re.search('html',file_list[i],flags=re.IGNORECASE)):\n",
    "                        out_list.append(file_list[i])\n",
    "\n",
    "            out_pd = pd.DataFrame(out_list)\n",
    "            out_pd.columns=['file']\n",
    "            out_pd['text'] = out_pd.apply(lambda x: extract_html('html/'+x['file']), axis=1)\n",
    "            out_pd['quarter'] = out_pd.apply(lambda x: extract_quarter(x['text']), axis=1)\n",
    "            out_pd['year'] = out_pd.apply(lambda x: extract_year(x['text']), axis=1)\n",
    "            # out_pd['quarter_year'] = out_pd.apply(lambda x: extract_q(x['text']), axis=1)\n",
    "            out_pd['executive_firm'] = out_pd.apply(lambda x: extract_firm(x['text']), axis=1)\n",
    "            out_pd['ticker'] = out_pd.apply(lambda x: extract_ticker(x['text']), axis=1)\n",
    "\n",
    "            out_pd['analysts'] = out_pd.apply(lambda x: extract_analysts(x['text']), axis=1)\n",
    "            out_pd['execs'] = out_pd.apply(lambda x: extract_executives(x['text']), axis=1)\n",
    "\n",
    "            s = out_pd.execs.apply(pd.Series)\\\n",
    "                          .stack()\\\n",
    "                          .reset_index(level=1, drop=True)\\\n",
    "                          .to_frame('executive')\n",
    "            out_executives = out_pd.join(s)                      \n",
    "\n",
    "\n",
    "            out_executives['exec_name'] = out_executives.apply(lambda x: extract_name(x['executive']), axis=1)\n",
    "            out_executives['exec_title'] = out_executives.apply(lambda x: extract_title(x['executive']), axis=1)\n",
    "\n",
    "            out_executives['executive_content'] = out_executives.apply(lambda x: \\\n",
    "                                                     extract_content(x['text'],x['exec_name']), axis=1)\n",
    "            out_executives['executive_qanda'] = out_executives.apply(lambda x: \\\n",
    "                                                     extract_qanda(x['text'],x['exec_name']), axis=1)\n",
    "\n",
    "            out_executives['exec_qna_count'] = out_executives.apply(lambda x: \\\n",
    "                                                     basic_wc(x['executive_qanda']), axis=1)\n",
    "\n",
    "            out_executives['exec_content_count'] = out_executives.apply(lambda x: \\\n",
    "                                                     basic_wc(x['executive_content']), axis=1)\n",
    "            out_executives['exec_total_count'] = out_executives.exec_qna_count + out_executives.exec_content_count\n",
    "\n",
    "            out_executives=out_executives.reset_index(level=0, drop=True)\n",
    "            # out_analyst\n",
    "            s = out_executives.execs.apply(pd.Series)\\\n",
    "                          .stack()\\\n",
    "                          .reset_index(level=1, drop=True)\\\n",
    "                          .to_frame('mention_name')\n",
    "            out_executives = out_executives.join(s)          \n",
    "            out_executives['mention_titile'] = out_executives.apply(lambda x: extract_title(x['mention_name']), axis=1)\n",
    "            out_executives['mention_name'] = out_executives.apply(lambda x: extract_name(x['mention_name']), axis=1)\n",
    "            out_executives['exec_mention_qna'] = out_executives.apply(lambda x: extract_name_pair(x['mention_name'],x['executive_qanda']), axis=1)\n",
    "            out_executives['exec_mention_transcript'] = out_executives.apply(lambda x: extract_name_pair(x['mention_name'],x['executive_content']), axis=1)\n",
    "            out_executives['mention_name_count_qna'] = out_executives.apply(lambda x: \\\n",
    "                                          len(x['exec_mention_qna']), axis=1)\n",
    "            out_executives['mention_name_count_transcript'] = out_executives.apply(lambda x: \\\n",
    "                                          len(x['exec_mention_transcript']), axis=1)\n",
    "            out_executives['mention_name_count_total']= out_executives.mention_name_count_qna+out_executives.mention_name_count_transcript\n",
    "#             print('here##')\n",
    "            # out_analyst.drop(['text','analyst_present','analysts','executive'],axis=1)\n",
    "            out_executives.drop(['text','executive','execs','exec_mention_qna',\\\n",
    "                                 'exec_mention_transcript'],axis=1)\\\n",
    "            .to_csv(filename,sep=',', encoding = 'utf-8',header=False)\n",
    "            # out_executives.select({[}'file','quarter_yer'])    \n",
    "            logwriter.writerow([ii,out_executives.file.head(1).item(),'success'])\n",
    "        except:\n",
    "            print('exception: ', ii, ' ###')\n",
    "            logwriter.writerow([ii,out_executives.file.head(1).item(),'fail'])\n",
    "            \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "fieldnames = ['index','fname', 'status']\n",
    "\n",
    "with open('log_extract.csv', 'wb') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile,delimiter='\\t',quotechar='\"',quoting=csv.QUOTE_NONE, fieldnames=fieldnames)\n",
    "    writer.writer(['test','test','success'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.html'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_analyst.file.head(1).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
